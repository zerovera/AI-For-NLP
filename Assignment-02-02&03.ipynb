{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment-02, Probability Model A First Look: An Introduction of Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment\n",
    "\n",
    "1. Review the course online programming code; \n",
    "2. Review the main questions; \n",
    "3. Using wikipedia corpus to build a language model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Review the main points of this lesson. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. How to Github and Why do we use Jupyter and Pycharm; "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 通过git；Jupyter支持实时代码、编辑公式，是一个很好用的交互式notebook；Pycharm在众多python的IDE中比较出名，并没有横向比较过，哈哈。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. What's the Probability Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:基于概率的模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Can you came up with some sceneraies at which we could use Probability Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:游戏里面的种种场景。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Why do we use probability and what's the difficult points for programming based on parsing and pattern match? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:基于概率的模型更多程度上不需要依赖于先验的知识。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. What's the Language Model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:语言模型就是用来计算一个句子的概率的模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  6. Can you came up with some sceneraies at which we could use Language Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:NLP里面的众多场景。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. What's the 1-gram language model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:当前词的出现概率与前后的词都无关。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8. What's the disadvantages and advantages of 1-gram language model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:假设不太合理不过计算简单。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9.  What't the 2-gram models; "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:当前词的出现概率与仅仅与前一个词有关。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10. what's the web crawler, and can you implement a simple crawler? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:按照一定的规则从网页爬取数据，之前经常去爬百度地图的数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 11.  There may be some issues to make our crwaler programming difficult, what are these, and how do we solve them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:同一IP访问次数限制、参数加密、复杂的JS等，见招拆招。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 12. What't the Regular Expression and how to use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:字符串匹配模式，python的话import re。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Using Wikipedia dataset to finish the language model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: You need to download the corpus from wikipedis:\n",
    "> https://dumps.wikimedia.org/zhwiki/20190401/\n",
    "\n",
    "Step 2: You may need the help of wiki-extractor:\n",
    "\n",
    "> https://github.com/attardi/wikiextractor\n",
    "\n",
    "Step 3: Using the technologies and methods to finish the language model; \n",
    "> \n",
    "\n",
    "Step 4: Try some interested sentence pairs, and check if your model could fit them\n",
    "\n",
    "总体来讲和课堂代码如出一辙，等计算资源中。\n",
    "\n",
    "Step 5: If we need to solve following problems, how can language model help us? \n",
    "\n",
    "+ Voice Recognization.\n",
    "估计需要一个类似jieba分词的语音频率切分工具，然后结合语言模型。\n",
    "+ Sogou *pinyin* input.\n",
    "把条件概率最高的显示出来就好了。\n",
    "+ Auto correction in search engine.\n",
    "模糊匹配加语音模型。\n",
    "+ Abnormal Detection.\n",
    "同上。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compared to the previous learned parsing and pattern match problems. What's the advantage and disavantage of Probability Based Methods? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 不需要专家知识，但是拟合度高的话（n-Gram的n比较大）需要大量语料以及计算资源。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional)  How to solve *OOV* problem?\n",
    "\n",
    "If some words are not in our dictionary or corpus. When we using language model, we need to overcome this `out-of-vocabulary`(OOV) problems. There are so many intelligent man to solve this probelm. \n",
    "\n",
    "-- \n",
    "\n",
    "The first question is: \n",
    "\n",
    "**Q1: How did you solve this problem in your programming task?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 赋予了一个很小的概率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the sencond question is: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2: Read about the 'Turing-Good Estimator', can explain the main points about this method, and may implement this method in your programming task**\n",
    "\n",
    "Reference: \n",
    "+ https://www.wikiwand.com/en/Good%E2%80%93Turing_frequency_estimation\n",
    "+ https://github.com/Computing-Intelligence/References/blob/master/NLP/Natural-Language-Processing.pdf, Page-37"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "coding in here\n",
    "    刚好书房有本《数学之美》，34页-38页有很详细的介绍，原理是对于没有看见的事件，我们不能认为它发生的概率就是零，要从概率总量中分配一个很小的比例给这些没有看见的实际，至于分配多少，则根据“越是不可信的统计折扣越多”的方法。以one-Gram为例："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$N=\\sum_{r=1}^n rN_r$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在假定r比较小时它的统计不可靠，因此在计算出现r次的词的概率时，使用的不是r而是一个更小的次数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$d_r=(r+1)N_{r+1}/N_r$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这样就给为出现的词赋予了一个很小的非零值，解决了零概率的问题，同时下调了出现频率很低的词的概率。实际工程上一般是只对出现次数低于某个阈值的词才下调，下调得到的频率总和分给未出现的词。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
